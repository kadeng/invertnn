{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.distributions as dists\n",
    "import invertnn.pytorch.invertible_transforms as invertible\n",
    "import invertnn.pytorch.orthogonal_transform as ortho\n",
    "\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "import torch.distributions as dists \n",
    "\n",
    "from invertnn.pytorch.orthogonal_transform import OrthogonalTransform, DiagonalLinearTransform, InvertibleLinear, InvertibleLinear\n",
    "from invertnn.pytorch.invertible_transforms import InvertibleModule, InvertibleConcatNoise, InvertibleCouplingLayer, InvertibleModuleTransform, InvertibleSequential, InvertibleBias, InvertibleView\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.distributions as dists\n",
    "import invertnn.pytorch.invertible_transforms as invertible\n",
    "import invertnn.pytorch.orthogonal_transform as ortho\n",
    "import invertnn.pytorch.white_noise as white_noise\n",
    "from unittest import TestCase\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import logging\n",
    "from invertnn.pytorch.white_noise import AdaptiveInverseWhiteningTransformer\n",
    "\n",
    "from torchvision.datasets import STL10, FashionMNIST\n",
    "import math\n",
    "import itertools\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmnist = FashionMNIST(root='./FashionMNIST', download=True, train=True)\n",
    "len(fmnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACBUlEQVR4nLXSz0tUURQH8O+597373rx545g6NmNJY6TlJgozEsKFZGCrkDBoVdGmdf9BiwJ3bVr1PwhBUbQfJQcKjWZRTsjo0KDpDPV+eN+997WK0Z2bvtsPfM+Bc4D/HwJycwBZAEAE6zAyfe5RFMQfFYiRAj+CXM/c2HK82VetVMM34RGUmCxz9v7yYnW9dnWyskyHR6azi72Jwep3ScVk9c7LLhKQrpRBSiI2n76puZFT3doUwH4pcmw/zpjrU2zw3dFt4XEWdvbKhpinzTBYt5bDH4qlLYO8cbKBWHOudDHluFtiLrLD0kmM2//6q9VFS+JLLDxv9GzMPV9v3XuzYgHEGSUGCngbRCLd4W6CxPCLHTDwVMkDA0y/qEa/lFFBoF2EEME8CAD6hsZK8+djlmSatuiXXsWfNh27NU6Yelro1bytPElRbaGaO1FGPfc7zPg9HvHlIaVD8AjID9y/+bgZ/6iP9ks7J/QZevh8w/cd2PlGs8CKt92R7MQEk0yA7GtWq9ETN3zRs7fpR7FaWi/3yXaipW1IjFnbaSM70N7dsRzbzbHd8aCx7+wmKskUO5esz0sPmvXYF67gBzoNfxptxb5stxM10iLg1pOTO23NhcUptW1hE6gFYYprC8QMMPNsMM+4pamVbps/HGkSsg+1Cv4d+0Jh//Sm3DjGix4rfwFoJNh2/0cDFgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x159E06CD3C8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmnist[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stl10 = STL10(root='./FashionMNIST', download=True, split='unlabeled')\n",
    "#len(stl10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stl10[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prod(iterable, startval=1):\n",
    "    \"\"\"Helper function, calculates the product of an iterable\"\"\"\n",
    "    val = startval\n",
    "    for i in iterable:\n",
    "        val *= i\n",
    "    return val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SimpleInvertibleGenerator(nn.Module):\n",
    "    \n",
    "    def __init__(self, img_shape=(1,28,28)):\n",
    "        super().__init__()\n",
    "        n = prod(img_shape)\n",
    "        self.imodel = invertible.InvertibleSequential(\n",
    "            OrderedDict([\n",
    "                    ('noise_1', InvertibleConcatNoise(dists.Normal(torch.zeros(10).to('cuda:0'), torch.ones(10).to('cuda:0')),\n",
    "                                                      size=10, name='input_sample')),\n",
    "                    ('linear_1', InvertibleLinear(n=10, bias=True)),\n",
    "                    ('act_1', invertible.InvertibleSELU()),\n",
    "                    ('linear_2', InvertibleLinear(n=10, bias=True)),\n",
    "                    ('act_2', invertible.InvertibleSELU()),\n",
    "                    ('linear_3', InvertibleLinear(n=10, bias=True)),\n",
    "                    ('act_4', invertible.InvertibleSELU()),\n",
    "                    ('linear_4', InvertibleLinear(n=10, bias=True)),\n",
    "                    ('act_4', invertible.InvertibleSigmoid()),\n",
    "                ]\n",
    "            )\n",
    "        )  \n",
    "    \n",
    "    def forward(self, inp):\n",
    "        return self.imodel.forward(inp)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleInvertibleGenerator()\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling noise_1 with input of shape torch.Size([2, 0])\n",
      "Sampled shape torch.Size([2, 10])\n",
      "Log Prob -24.939050\n",
      "Calling linear_1 with input of shape torch.Size([2, 10])\n",
      "Calling U with input of shape torch.Size([2, 10])\n",
      "Calling S with input of shape torch.Size([2, 10])\n",
      "Calling V with input of shape torch.Size([2, 10])\n",
      "Calling act_1 with input of shape torch.Size([2, 10])\n",
      "Calling linear_2 with input of shape torch.Size([2, 10])\n",
      "Calling U with input of shape torch.Size([2, 10])\n",
      "Calling S with input of shape torch.Size([2, 10])\n",
      "Calling V with input of shape torch.Size([2, 10])\n",
      "Calling act_2 with input of shape torch.Size([2, 10])\n",
      "Calling linear_3 with input of shape torch.Size([2, 10])\n",
      "Calling U with input of shape torch.Size([2, 10])\n",
      "Calling S with input of shape torch.Size([2, 10])\n",
      "Calling V with input of shape torch.Size([2, 10])\n",
      "Calling act_4 with input of shape torch.Size([2, 10])\n",
      "Calling linear_4 with input of shape torch.Size([2, 10])\n",
      "Calling U with input of shape torch.Size([2, 10])\n",
      "Calling S with input of shape torch.Size([2, 10])\n",
      "Calling V with input of shape torch.Size([2, 10])\n",
      "Max difference 0.000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with invertible.InferenceContext() as ic:\n",
    "    res = model.forward(torch.ones((2,0)).to('cuda:0'))\n",
    "    \n",
    "    input_sample = ic.side_inputs['input_sample']\n",
    "    assert('input_sample' not in ic.reconstructed_side_inputs)\n",
    "    restored = model.imodel.invert(res)\n",
    "    \n",
    "    restored_sample = ic.reconstructed_side_inputs['input_sample']\n",
    "    error = (input_sample - restored_sample).abs().max()\n",
    "    print(\"Max difference %f\" % (error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2056,  1.8611,  0.6372,  0.6467,  0.0790,  1.0157, -0.3161, -2.1013,\n",
       "         -0.7796, -0.9845],\n",
       "        [ 0.3448, -0.7178,  0.0283, -0.6479,  0.9502, -0.2250, -2.1621, -0.9078,\n",
       "          0.6243, -1.8953]], device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2056,  1.8611,  0.6372,  0.6467,  0.0790,  1.0157, -0.3161, -2.1013,\n",
       "         -0.7796, -0.9845],\n",
       "        [ 0.3448, -0.7178,  0.0283, -0.6479,  0.9502, -0.2250, -2.1621, -0.9078,\n",
       "          0.6243, -1.8953]], device='cuda:0', grad_fn=<SplitWithSizesBackward>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restored_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32mc:\\users\\vw6z1lw\\pycharmprojects\\invertnn\\invertnn\\pytorch\\invertible_transforms.py\u001b[0m(469)\u001b[0;36minvert\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m    467 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    468 \u001b[1;33m    \u001b[1;32mdef\u001b[0m \u001b[0minvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m--> 469 \u001b[1;33m        \u001b[0msample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_size_or_sections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    470 \u001b[1;33m        \u001b[0mrestored_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    471 \u001b[1;33m        \u001b[0mrestored_sample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribution\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestored_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> output.split\n",
      "<bound method Tensor.split of tensor([[-0.4975, -0.7502, -1.6006, -2.1392,  0.5006,  0.1140, -0.4401,  0.0491,\n",
      "         -0.1484, -0.9491],\n",
      "        [ 0.0144,  0.3006,  0.2407, -0.0342, -0.2196,  0.2167, -0.2265, -2.0266,\n",
      "         -0.9538,  0.9299]], device='cuda:0', grad_fn=<CopyBackwards>)>\n",
      "ipdb> cont\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
